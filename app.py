# app.py
import os
import streamlit as st
from dotenv import load_dotenv

from agent import AIGCTeachingAssistantAgent
from openai import OpenAI
from PIL import Image
from io import BytesIO

load_dotenv()

st.set_page_config(page_title="AIGC èª²ç¨‹å°åŠ©æ•™", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– AIGC èª²ç¨‹å°åŠ©æ•™ Agentï¼ˆæ‘˜è¦ / æ¸¬é©— / å°é¢åœ–ï¼‰")

with st.expander("ä½œæ¥­ç¹³äº¤æé†’ï¼ˆä½ è¦äº¤ä»€éº¼ï¼‰", expanded=True):
    st.markdown("""- **(1) report æ‘˜è¦ 300 å­—ï¼ˆABSTRACTï¼‰**
- **(2) agent é–‹ç™¼éç¨‹å°è©±ç´€éŒ„**
- **(3) GitHub repo ï¼‹ Streamlit.app ç·šä¸Š demo**

ä½ å¯ä»¥æŠŠæœ¬å°ˆæ¡ˆç›´æ¥ç•¶æˆ demoï¼šè²¼ä¸Šèª²å ‚å…§å®¹ â†’ ä¸€éµç”Ÿæˆä¸‰ç¨®è¼¸å‡ºã€‚
""")

api_key = st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None
api_key = api_key or os.getenv("OPENAI_API_KEY")

colL, colR = st.columns([1.2, 1])

with colL:
    notes = st.text_area("è²¼ä¸Šèª²å ‚ç­†è¨˜/è¬›ç¾©å…§å®¹ï¼ˆè¶Šå®Œæ•´è¶Šå¥½ï¼‰", height=260, placeholder="ä¾‹å¦‚ï¼šæœ¬é€±ä»‹ç´¹ Transformerã€æ“´æ•£æ¨¡å‹ã€æç¤ºè©å·¥ç¨‹ã€RAG ...")
    model = st.selectbox("æ–‡å­—æ¨¡å‹ï¼ˆå¯æ”¹ï¼‰", ["gpt-4o-mini", "gpt-4.1-mini", "gpt-4o"], index=0)
    gen_image = st.checkbox("åŒæ™‚ç”Ÿæˆå°é¢åœ–ï¼ˆéœ€è¦åœ–åƒ APIï¼‰", value=True)

run = st.button("ğŸš€ ç”Ÿæˆï¼ˆæ‘˜è¦ï¼‹æ¸¬é©—ï¼‹å°é¢æç¤ºè©ï¼‰", type="primary", use_container_width=True)

if run:
    agent = AIGCTeachingAssistantAgent(api_key=api_key, model=model)
    result = agent.run(notes)

    with colR:
        st.subheader("1) 300 å­—å…§æ‘˜è¦")
        st.write(result.summary)
        st.download_button("ä¸‹è¼‰æ‘˜è¦ txt", data=result.summary, file_name="abstract.txt")

        st.subheader("2) æ¸¬é©—ï¼ˆå«ç­”æ¡ˆï¼‰")
        st.write(result.quiz)
        st.download_button("ä¸‹è¼‰æ¸¬é©— txt", data=result.quiz, file_name="quiz.txt")

        st.subheader("3) å°é¢åœ–åƒæç¤ºè©ï¼ˆA/B/C ä¸‰ç¨®é¢¨æ ¼ï¼‰")
        st.write(result.cover_prompt)
        st.download_button("ä¸‹è¼‰å°é¢æç¤ºè© txt", data=result.cover_prompt, file_name="cover_prompt.txt")

    if gen_image:
        st.divider()
        st.subheader("å°é¢åœ–ï¼ˆä½¿ç”¨ OpenAI Images APIï¼›æ²’æœ‰ key æœƒç•¥éï¼‰")

        if not api_key:
            st.info("å°šæœªè¨­å®š OPENAI_API_KEY â†’ ç›®å‰ä¸ç”¢ç”Ÿåœ–ç‰‡ï¼ˆä½†æ–‡å­—è¼¸å‡ºä»å¯ç”¨ç¤ºç¯„æ¨¡å¼ï¼‰ã€‚")
        else:
            # å– B é¢¨æ ¼ç•¶é è¨­ï¼Œè®“ç•«é¢æ›´å¸ç›
            prompt_lines = [line.strip() for line in result.cover_prompt.splitlines() if line.strip()]
            img_prompt = None
            for line in prompt_lines:
                if line.startswith("B:"):
                    img_prompt = line.replace("B:", "").strip()
                    break
            img_prompt = img_prompt or prompt_lines[0].split(":",1)[-1].strip()

            client = OpenAI(api_key=api_key)
            with st.spinner("ç”Ÿæˆåœ–ç‰‡ä¸­..."):
                img = client.images.generate(
                    model="gpt-image-1",
                    prompt=img_prompt,
                    size="1024x1024",
                )
            b64 = img.data[0].b64_json
            image_bytes = BytesIO(__import__("base64").b64decode(b64))
            image = Image.open(image_bytes)

            st.image(image, caption="Generated cover image", use_container_width=False)
            buf = BytesIO()
            image.save(buf, format="PNG")
            st.download_button("ä¸‹è¼‰å°é¢åœ– PNG", data=buf.getvalue(), file_name="cover.png", mime="image/png")

st.caption("æç¤ºï¼šä½ å¯ä»¥æŠŠç”Ÿæˆçš„æ‘˜è¦è²¼é€² reportï¼›æŠŠä½ èˆ‡æœ¬ app çš„äº’å‹•æˆªåœ–/è²¼é€² sample_dialogue.md ç•¶ä½œ agent å°è©±ç´€éŒ„ã€‚")
